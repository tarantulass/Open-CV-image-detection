{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc88182-de01-462f-a0e6-9caab3af2d82",
   "metadata": {},
   "source": [
    "Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52eabfe-3546-4cd8-9a5e-d2d38b770b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1d2bc6-4da8-49c5-8ce2-47a1881694c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Documents/b.webp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f310fa8-ec48-44fa-8dea-517398be59b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "cv.imshow('cat',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d4b82f-80d5-4fc5-8d8c-1cbf0eeb4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(frame,scale):\n",
    "    width = int(frame.shape[1]*scale)\n",
    "    height = int(frame.shape[0]*scale)\n",
    "    dim = (width,height)\n",
    "    return cv.resize(frame,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84015825-f321-4cff-b2a8-a30f77b28f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "reimg = rescale(img,0.6)\n",
    "cv.imshow('cat2.0',reimg)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e00583c6-8c3b-4744-8096-6837747ed3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros((500,500,3),dtype = 'uint8')\n",
    "\n",
    "cv.imshow('rgb',blank)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5ec4ed-f46c-4bbf-ae98-5d2035176820",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank[200:300,300:400] = 0,0,255\n",
    "\n",
    "cv.imshow('rgb',blank)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506b18f1-ce25-4570-ac80-a5837aa5e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Documents/a.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491d4b32-cd05-464c-b2a3-fc10e1e328eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gimg = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('grayscale',gimg)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796043c7-70f3-4515-8fef-1a3a77dd835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank[250:250,500:500] = 0,255,0\n",
    "cv.imshow('green',blank)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb95b26-c332-4b6f-8194-11559d0bba2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ad2b0c0-e355-477f-9323-e692214379d0",
   "metadata": {},
   "source": [
    "BLURRING an image kind of reducing the information - reducing the noise\n",
    "for now we use gaussian blur there r many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a00f7bad-3ebb-492c-9eae-7129810d4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur1 = cv.GaussianBlur(img,(5,5),cv.BORDER_DEFAULT)\n",
    "#here we have to pass in a odd kernel increasing dimension decreases the distinction between adjacent pixels\n",
    "cv.imshow('blur',blur1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('blur')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce769ff-970e-4ae3-bc43-93ac5cb721e7",
   "metadata": {},
   "source": [
    "Edge cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "813e86b7-b4ec-49c3-bddd-faa5089dd7b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/highgui/src/window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m num,frame \u001b[38;5;241m=\u001b[39m dp\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      4\u001b[0m abc \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mCanny(frame,\u001b[38;5;241m125\u001b[39m,\u001b[38;5;241m175\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mface\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mabc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/highgui/src/window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "dp = cv.VideoCapture(1)\n",
    "while True:\n",
    "    num,frame = dp.read()\n",
    "    abc = cv.Canny(frame,125,175)\n",
    "\n",
    "    cv.imshow('face',abc)\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF == ord('a'):\n",
    "        break\n",
    "dp.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d1a2521-ca84-4fa1-a7bf-4b41d499c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cannyimg = cv.Canny(img,125,175)\n",
    "cv.imshow('face',cannyimg)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565c5dff-57f0-4b19-8bf2-3882ee459f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cannyimg = cv.Canny(blur1,125,175)\n",
    "cv.imshow('blur2',cannyimg)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('blur2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7fbc78-14f2-4d3b-9828-ba8dadf46248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dilating using a structuring element i.e edges (canny edges)\n",
    "dilated = cv.dilate(cannyimg,(3,3),iterations = 4)\n",
    "cv.imshow('blur2',dilated)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('blur2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "103205b7-2b1d-4b39-87d4-1bce5efe0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv.erode(dilated,(5,5),iterations = 20)\n",
    "cv.imshow('eroded',eroded)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('eroded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b1e4f3-a420-4b8c-90f0-bc90fb07cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv.erode(dilated,(5,5),iterations = 2)\n",
    "cv.imshow('eroded',eroded)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('eroded')\n",
    "#here increasing th enumber of iterations just reduces  the noise or minute details in the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b96528f3-bfa3-42c3-9ded-3f3a7d8a3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = cv.resize(eroded,(500,1000))\n",
    "cv.imshow('resized',resize)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caf5010a-3981-4170-9e6f-808a517e0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = cv.resize(eroded,(100,100),interpolation = cv.INTER_AREA)\n",
    "cv.imshow('resized',resize)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('resized')\n",
    "#we use interpolation in the case where the final picture to be displayed is smaller/larger than the actual size\n",
    "#we use linear,cubic for more and inter_Area for less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96e3f632-dc77-47c1-97ad-6cf92b2ca9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translated(img,x,y):\n",
    "    transmat = np.float32([[1,0,x],[0,1,y]])\n",
    "    dimensions = (img.shape[1],img.shape[0])\n",
    "    return cv.warpAffine(img,transmat,dimensions)\n",
    "    \n",
    "t_img = translated(img,100,-100)\n",
    "cv.imshow('translated',t_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('translated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3c18d7c-3dd1-4952-b501-7481e19b014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img,angle,rotpoint):\n",
    "    #img.shape[:2] = (height,width) -> wrong why???\n",
    "    (height,width) = img.shape[:2] \n",
    "\n",
    "    if rotpoint is None:\n",
    "        rotpoint = (width//2,height//2)\n",
    "    rotmat = cv.getRotationMatrix2D(rotpoint,angle,1.0)#scaling at last\n",
    "    dimensions = (width,height)\n",
    "\n",
    "    return cv.warpAffine(img,rotmat,dimensions)\n",
    "\n",
    "r_img = rotate(img,30,None)\n",
    "cv.imshow('rotated',r_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyWindow('rotated')\n",
    "#rotating a rotated image results in a skewed image\n",
    "#remember here that when we try to rotate an already rotated image then we also try to rotate the black area!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2d692c5-bade-4233-a2dc-20228b7b9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_img = cv.flip(img,-1)\n",
    "cv.imshow('flip',f_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3f494-f73b-41d2-9521-06049c3b3e6c",
   "metadata": {},
   "source": [
    "Now about flipping virat kohli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c46c68f0-95ac-4db5-ad5d-9ae23910f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vk = cv.VideoCapture('Videos/Screencasts/Screencast from 16-05-24 08:26:28 PM IST.webm')\n",
    "while True:\n",
    "    num,frames = vk.read()\n",
    "    f_frames = cv.flip(frames,1)\n",
    "    cv.imshow('vk_lefty',f_frames)\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF == ord('v'):\n",
    "        break\n",
    "vk.release()\n",
    "cv.destroyAllWindows()\n",
    "#0 for along x axis\n",
    "#1 for along y axis\n",
    "#-1 for both along x,y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aff565-8eb8-4b34-8c0d-de599c679bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
